{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/social-\n",
      "[nltk_data]     sim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/social-\n",
      "[nltk_data]     sim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Information System Forensics, Information Syst...\n",
      "1    Information System Forensics (Criminal) and Ma...\n",
      "2    Information System Forensics, Information Syst...\n",
      "3    Information System Forensics, Information Syst...\n",
      "4    Information System Forensics, Information Syst...\n",
      "Name: user.description_m.keyword: Descending, dtype: object\n",
      "['provide', 'following', 'services', 'security', 'software', 'vulnerability', 'assessment', 'review', 'cybersecurity', 'assessment']\n",
      "['interest', 'include', 'economics', 'finance', 'sport', 'movie', '1930s', 'history']\n",
      "['equipo', 'tecnonators']\n",
      "['security', 'SCREEN_NAME', 'jnj_cxagp1p1jo2yuyhbqq', 'cissp', 'sharing', 'infosec', 'friendly', 'followers', 'cybersecurity', 'secret', 'weapon', 'business', 'success']\n",
      "['working', 'microsoft', 'security', 'program', 'manager', 'interest', 'software', 'security', 'fighting', 'malware', 'phishing']\n",
      "['cyber', 'security', 'ninja', 'ethical', 'hacker', 'pent', 'application', 'security']\n",
      "['cyber', 'security', 'professional', 'pent', 'infosec']\n",
      "['itsec', 'analyst', 'speaker', 'instructor', 'veteran', 'analyste', 'nouvelles', 'secti', 'conférencier', 'instructeur', 'vétéran']\n",
      "(0, '0.073*\"security\" + 0.073*\"interest\" + 0.040*\"software\" + 0.040*\"manager\"')\n",
      "(1, '0.133*\"security\" + 0.092*\"pent\" + 0.092*\"cyber\" + 0.050*\"hacker\"')\n",
      "(2, '0.069*\"assessment\" + 0.038*\"veteran\" + 0.038*\"analyst\" + 0.038*\"conférencier\"')\n",
      "(3, '0.050*\"infosec\" + 0.050*\"cybersecurity\" + 0.050*\"cissp\" + 0.050*\"sharing\"')\n",
      "(4, '0.092*\"equipo\" + 0.092*\"tecnonators\" + 0.015*\"security\" + 0.015*\"infosec\"')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/social-sim/.local/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_html() missing 1 required positional argument: 'fileobj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-03977aa93f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mlda_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_html() missing 1 required positional argument: 'fileobj'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys \n",
    "import random\n",
    "import spacy\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim import corpora\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_ = '/home/social-sim/Documents/SocialSimCodeTesting/TH/TH-analysis/Data/user_variables/sample.csv'\n",
    "user_attr = pd.read_csv(file_)\n",
    "texts = user_attr[\"user.description_m.keyword: Descending\"]\n",
    "print(texts.head())\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "\ttry:\n",
    "\t\ttokens = tokenize(text)\n",
    "\t\ttokens = [token for token in tokens if len(token) > 4]\n",
    "\t\ttokens = [token for token in tokens if token not in en_stop]\n",
    "\t\ttokens = [get_lemma(token) for token in tokens]\n",
    "\t\treturn tokens\n",
    "\texcept:\n",
    "\t\tprint(pd.isnull(text))\n",
    "\t\tsys.exit()\n",
    "\n",
    "\n",
    "text_data = []\n",
    "for line in texts.values.tolist():\n",
    "\tif not pd.isnull(line):\n",
    "\t\ttokens = prepare_text_for_lda(line)\n",
    "\t\tif random.random() > .99:\n",
    "\t\t\tprint(tokens)\n",
    "\t\t\ttext_data.append(tokens)\n",
    "\telse:\n",
    "\t\tcontinue\n",
    "\n",
    "\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')\n",
    "\n",
    "\n",
    "\n",
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model5.gensim')\n",
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)\n",
    "#pyLDAvis.save_html(lda_display)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6798d9128f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
